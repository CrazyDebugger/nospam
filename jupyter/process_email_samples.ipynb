{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "import os\n",
    "import stat\n",
    "import pandas as pd\n",
    "\n",
    "def read_email(filename):\n",
    "    '''\n",
    "    Read Email content.\n",
    "    :param filename: Path to the file\n",
    "    :return: Subject and content\n",
    "    '''\n",
    "    with open(filename, encoding='latin-1') as f:\n",
    "        mail = email.message_from_file(f)\n",
    "        payload = mail.get_payload()\n",
    "        if type(payload) == type(list()):\n",
    "            payload = payload[0]\n",
    "        if type(payload) != type(''):\n",
    "            payload = str(payload)\n",
    "            \n",
    "        subject = mail.get('subject')\n",
    "        subject_str = str(subject)\n",
    "        return subject_str + payload\n",
    "\n",
    "def get_file_id(filename):\n",
    "    '''\n",
    "    Get file id.\n",
    "    :param filename: Path to the file\n",
    "    :return: The id of the file\n",
    "    '''\n",
    "    return int(re.findall(r'\\d+', filename)[0])\n",
    "\n",
    "def clean_html(raw_text):\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def get_label(labels, index):\n",
    "    '''\n",
    "    Get emails tag.\n",
    "    :param labels: Id and prediction\n",
    "    :return: 1 for ham，0 for spam\n",
    "    '''\n",
    "    return labels.Prediction[labels.Id == index].iloc[0]\n",
    "    \n",
    "def calc_tf_idf(tf, idf, text, ignore=3):\n",
    "    '''\n",
    "    Calculate term frequency and inverse document frequency.\n",
    "    :param tf: Term frequency\n",
    "    :param idf: Inverse document frequency\n",
    "    :return: words count\n",
    "    '''\n",
    "    words = re.findall('\\w+', text)\n",
    "    count = 0\n",
    "    word_set = set()\n",
    "    for word in words:\n",
    "        # Filter invalid words\n",
    "        if len(word) < ignore or len(word) > 20:\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        \n",
    "        # Calculate inverse document frequency\n",
    "        if not (word in word_set):\n",
    "            idf[word] = idf.get(word, 0) + 1\n",
    "            word_set.add(word)\n",
    "            \n",
    "        # Calculate words count\n",
    "        tf[word] = tf.get(word, 0) + 1\n",
    "        \n",
    "        # Calculate total words count\n",
    "        count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def train_model():\n",
    "    '''\n",
    "    Read emails and tags.\n",
    "    :return: All the information we need.\n",
    "    '''\n",
    "    pathname = 'TR'\n",
    "    labels = pd.read_csv('spam-mail.tr.label')\n",
    "    \n",
    "    ham_tf = dict()\n",
    "    spam_tf = dict()\n",
    "    word_idf = dict()\n",
    "    ham_word_count = 0\n",
    "    spam_word_count = 0\n",
    "    file_count = 0\n",
    "    spam_file_count = 0\n",
    "    ham_file_count = 0\n",
    "    \n",
    "    # Iterate over emails\n",
    "    for file in os.listdir(pathname):\n",
    "        fpath = os.path.join(pathname, file)\n",
    "        info = os.stat(fpath)\n",
    "        if stat.S_ISREG(info.st_mode) and file.endswith('.eml'):\n",
    "            '''\n",
    "            1. Read content\n",
    "            2. According to the tags, calculate words count and so on.\n",
    "            '''\n",
    "            text = clean_html(read_email(fpath))\n",
    "            index = get_file_id(file)\n",
    "            file_count = file_count + 1\n",
    "            if get_label(labels, index) == 1:\n",
    "                ham_file_count = ham_file_count + 1\n",
    "                ham_word_count = ham_word_count + calc_tf_idf(ham_tf, word_idf, text)\n",
    "            else:\n",
    "                spam_file_count = spam_file_count + 1\n",
    "                spam_word_count = spam_word_count + calc_tf_idf(spam_tf, word_idf, text)\n",
    "\n",
    "    info = {}\n",
    "    info['ham_word_count'] = ham_word_count\n",
    "    info['spam_word_count'] = spam_word_count\n",
    "    info['file_count'] = file_count\n",
    "    info['ham_file_count'] = ham_file_count\n",
    "    info['spam_file_count'] = spam_file_count\n",
    "    print('train email info : ', info)\n",
    "\n",
    "    # Transpose\n",
    "    word_df = pd.DataFrame([ham_tf, spam_tf, word_idf]).T\n",
    "    word_df.columns = ['ham_tf', 'spam_tf', 'word_idf']\n",
    "    return (word_df, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train email info :  {'ham_word_count': 448008, 'spam_word_count': 351808, 'file_count': 2500, 'ham_file_count': 1721, 'spam_file_count': 779}\n"
     ]
    }
   ],
   "source": [
    "email_df, email_info = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ham_tf   spam_tf  word_idf   spam_sp\n",
      "hibody         0.000002  0.001168     214.0  0.995797\n",
      "111n           0.000002  0.001083       8.0  0.995467\n",
      "0px            0.000004  0.001768     204.0  0.994453\n",
      "111r           0.000002  0.000881       7.0  0.994435\n",
      "11px           0.000002  0.000770     107.0  0.993639\n",
      "...                 ...       ...       ...       ...\n",
      "dd3960         0.000002  0.000045       2.0  0.902178\n",
      "118i           0.000002  0.000045       7.0  0.902178\n",
      "tabdesmond61a  0.000002  0.000045       2.0  0.902178\n",
      "heat           0.000013  0.000270      23.0  0.901250\n",
      "farmer         0.000007  0.000134      13.0  0.900304\n",
      "\n",
      "[531 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 拷贝数据，可重复运行这段代码\n",
    "word_df = email_df.copy()\n",
    "word_df.fillna(1, inplace=True)    \n",
    "\n",
    "# P(Y=S) : 垃圾邮件的概率\n",
    "p_y_s = email_info['spam_file_count'] /  email_info['file_count']\n",
    "\n",
    "# P(Y=H) : 正常邮件的概率\n",
    "p_y_h = 1 - p_y_s\n",
    "\n",
    "# P(W|Y=H) : 正常邮件时，出现单词 W 的概率\n",
    "word_df['ham_tf'] = word_df['ham_tf'] / email_info['ham_word_count']\n",
    "\n",
    "# P(W|Y=S) : 垃圾邮件时，出现单词 W 的概率\n",
    "word_df['spam_tf'] = word_df['spam_tf'] / email_info['spam_word_count']\n",
    "\n",
    "# 根据公式计算 P(Y=S|W)\n",
    "word_df['spam_sp'] = (word_df['spam_tf'] * p_y_s) / (word_df['ham_tf'] * p_y_h + word_df['spam_tf'] * p_y_s)\n",
    "\n",
    "# 根据公式计算 P(Y=H|W)\n",
    "# word_df['spam_hp'] = (word_df['ham_tf'] * p_y_h) / (word_df['ham_tf'] * p_y_h + word_df['spam_tf'] * p_y_s)\n",
    "\n",
    "# 选择 P(Y=S|W) >= 0.9 的单词作为识别关键词，节省计算\n",
    "word_df = word_df.loc[(word_df['spam_sp'] >= 0.9)]\n",
    "\n",
    "# 从大到小排序\n",
    "word_df = word_df.sort_values(by=['spam_sp'], ascending=[False])\n",
    "\n",
    "print(word_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_spam_email(filename, word_df, info, ignore=3):\n",
    "    '''\n",
    "    Test if a given email is spam\n",
    "    :param filename: Path to email\n",
    "    :param word_df: word dataframe\n",
    "    :param info: word info\n",
    "    '''\n",
    "    text = clean_html(read_email(filename))\n",
    "    words = re.findall('[A-Za-z]+', text)\n",
    "    word_set = set()\n",
    "    p_s_w = info['spam_file_count'] /  info['file_count']\n",
    "    p_h_w = 1 - p_s_w\n",
    "    \n",
    "    for word in words:\n",
    "        # Ignore invalid words\n",
    "        if len(word) < ignore or len(word) > 20:\n",
    "            continue\n",
    "            \n",
    "        word = word.lower()\n",
    "\n",
    "        # Test if it is spam\n",
    "        if (word in word_df.index) and not (word in word_set):\n",
    "            word_set.add(word)\n",
    "            p_s_w = 1000 * p_s_w * (word_df.loc[word].spam_tf)\n",
    "            p_h_w = 1000 * p_h_w * (word_df.loc[word].ham_tf)\n",
    "\n",
    "    # Cannot verify, ham\n",
    "    if len(word_set) == 0:\n",
    "        return (False, 0)\n",
    "\n",
    "    # print('file %s p_s_w : %f, p_h_w %f, word count %d' % (filename, p_s_w, p_h_w, len(word_set)))\n",
    "    result = p_s_w / (p_s_w + p_h_w)\n",
    "    if result > 0.9:\n",
    "        return (True, result)\n",
    "    return (False, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.905149443323536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_spam_email('TR/TRAIN_168.eml', word_df, email_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "\n",
    "def read_email2(filename):\n",
    "    '''\n",
    "    Read Email content.\n",
    "    :param filename: Path to the file\n",
    "    :return: Subject and content\n",
    "    '''\n",
    "    with open(filename, encoding='latin-1') as f:\n",
    "        mail = email.message_from_file(f)\n",
    "        payload = ''\n",
    "        for part in mail.walk():\n",
    "            # Only process email parts in plain text and html\n",
    "            if part.get_content_type() == 'text/plain' or part.get_content_type() == 'text/html':\n",
    "                payload += str(part.get_payload())\n",
    "\n",
    "        subject = mail.get('subject')\n",
    "        sender = mail.get('from')\n",
    "        subject_str = str(subject)\n",
    "        return (subject_str, sender, payload)\n",
    "\n",
    "for i in range(1, 2500):\n",
    "    read_email2('TR/TRAIN_{}.eml'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dsl\n",
    "# This is a comment\n",
    "if mail.content has `some-word` then\n",
    "    LS = 0.1\n",
    "    LN = 0.2\n",
    "\n",
    "if mail.from eq/== `some-user` then\n",
    "    LS = 0.0\n",
    "    LN = 1.0\n",
    "\n",
    "if mail.subject has `some-word` then\n",
    "    LS = 0.1\n",
    "    LN = 0.3\n",
    "\n",
    "# Extension\n",
    "if mail.subject match `some-pattern` then\n",
    "    LS = 0.1\n",
    "    LN = 0.3\n",
    "```\n",
    "\n",
    "dsl -> dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mail'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1abc990c0478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEMail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceiver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         '''\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mail'"
     ]
    }
   ],
   "source": [
    "import mail\n",
    "\n",
    "class EMail(object):\n",
    "    def __init__(self, subject, sender, receiver, content):\n",
    "        '''\n",
    "        :param subject: Subject of the email.\n",
    "        :param sender: Sender of the email.\n",
    "        :param receiver: Receiver of the email.\n",
    "        :param content: Content of the email.\n",
    "        :returns: Mail object.\n",
    "        '''\n",
    "        self.subject = subject\n",
    "        self.sender = sender\n",
    "        self.receiver = receiver\n",
    "        self.content = content\n",
    "\n",
    "    def from_file(filename):\n",
    "        '''\n",
    "        :param filename: Path to the email file.\n",
    "        :returns: Mail object.\n",
    "        '''\n",
    "        with open(filenam, encodng='latin-1') as f:\n",
    "            mail = email.message_from_file(f)\n",
    "            content = ''\n",
    "            for part in mail.walk():\n",
    "                # Only process email parts in plain text and html\n",
    "                if part.get_content_type() == 'text/plain' or part.get_content_type() == 'text/html':\n",
    "                    content += str(part.get_payload())\n",
    "            subject = mail.get('subject')\n",
    "            sender = mail.get('from')\n",
    "            receiver = mail.get('to')\n",
    "            subject = str(subject)\n",
    "            return EMail(subject, sender, receiver, content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
